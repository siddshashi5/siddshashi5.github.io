<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 4 - Panorama Stitching</title>
    <style>
        body {
            font-family: 'Helvetica Neue', Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
            color: #333;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        h1 {
            color: #222;
            text-align: center;
            font-size: 2.5em;
            margin-bottom: 20px;
            font-weight: 300;
        }

        h2 {
            color: #444;
            font-size: 1.8em;
            margin-top: 40px;
            margin-bottom: 15px;
            font-weight: 400;
        }

        p {
            font-size: 1.1em;
            line-height: 1.8;
            margin-bottom: 20px;
        }

        .image-row {
            display: flex;
            justify-content: space-between;
            gap: 20px;
            flex-wrap: wrap;
            margin-bottom: 40px;
        }

        figure {
            flex: 1;
            text-align: center;
            margin: 0;
            border: 1px solid #ddd;
            padding: 10px;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            transition: box-shadow 0.3s ease;
        }

        figure:hover {
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
        }

        img {
            width: 100%;
            height: auto;
            border-radius: 8px;
        }

        .grey-image-row {
            display: flex;
            justify-content: space-between;
            gap: 20px;
            flex-wrap: wrap;
            margin-bottom: 40px;
        }

        /* .grey-image-row img{
            /* filter: grayscale(100%); */
        } */

        figcaption {
            font-size: 0.9em;
            color: #666;
            margin-top: 10px;
        }

        @media (max-width: 768px) {
            .image-row {
                flex-direction: column;
                gap: 10px;
            }
        }
    </style>
</head>
<body>

    <div class="container">
        <h1>Siddharth Shashi: Project 4 - Panorama Stitching</h1>

        <h2>Description</h2>
        <p>
            This project is all about stitching together many photographs taken from the same vantage point to create larger 
            composite images. 

            In the first part, I manually defined correspondences between photographs, warped them using those correspondences, 
            and then stitched and blended the warps together. 
            
            In the second part, I automated the correspondence definition by creating image descriptors for interest points 
            and choosing appropriate interest points as the basis for my image warping.
        </p>
        
        <h2>Creating the Homography Matrix</h2> 
        <p>
            After labeling corresponding points on two images, I needed to create the homography matrix H to warp the first image
            to the second. This involved solving a system of equations of 8 variables meaning that I needed at least 4 (x, y) 
            correspondences. Since even small errors in correspondence labeling result in drastically different homography matrices, 
            I created an overcomplete system with 6 correspondences and solved for an approximate solution with least squares. 
        </p>

        <h2>Image Warping</h2>
        <p>
            Similar to how I used affine transformations in my face warping project, I warped images with the homographic matrix using
            an inverse warp. I would get the corners of the warped image as the range I wanted to warp onto and used scipy.interpolate's
            griddata to linearly interpolate pixel intensities from the original image to get the appropriate colors. 
        </p>
        
        <div class="image-row">
            <figure>
                <img src="media/photos/anchor_house_bottom.jpg" alt="anchor_house_bottom">
                <figcaption>Anchor House Bottom Unwarped</figcaption>
            </figure>

            <figure>
                <img src="media/photos/anchor_house_bottom_warped.jpg" alt="anchor_house_bottom_warped">
                <figcaption>Anchor House Bottom Warped</figcaption>
            </figure>
        </div>

        <h2>Rectifying Images</h2>
        <p>
            Now that I could perspective warp images, I used my function to rectify images. Given an image of tiles taken at an angle, I
            put in coordinates that the tile corners would have as if the image was taken from above, and warped the image to those 
            correspondences. 
        </p>
        
        <div class="image-row">
            <figure>
                <img src="media/photos/tiles.jpg" alt="tiles">
                <figcaption>Tiles Unwarped</figcaption>
            </figure>

            <figure>
                <img src="media/photos/rectified_tiles.jpg" alt="rectified_tiles">
                <figcaption>Tiles Warped</figcaption>
            </figure>
        </div>

        <h2>Image Stitching</h2>
        <p>
            After I had the warped images, I overlaid them with two-band blending. To align the images in their appropriate locations, I
            used my defined corresponding points to pad and align the images for me to then overlay them. For the overlap regions, I used 
            two blending methods: simple alpha blending and two-band blending. For simple alpha blending, I had an alpha factor which 
            determined the contribution of each image for the overlap's pixel intensities. For two-band blending, I first separated the 
            images into their high- and low-frequency components. I had the overlap only consist of one of the image's high frequency 
            components but the low-frequency components would be blended with an alpha filter. 
        </p>

        <div class="image-row">
            <figure>
                <img src="media/photos/stitched_building_two_band.jpg" alt="stitched_building_two_band">
                <figcaption>Anchor House Stitched w/ Two-band</figcaption>
            </figure>

            <figure>
                <img src="media/photos/stitched_building_alpha.jpg" alt="stitched_building_alpha">
                <figcaption>Anchor House Stitched w/ Alpha</figcaption>
            </figure>
        </div>

        <div class="image-row">
            <figure>
                <img src="media/photos/stitched_moff_alpha.jpg" alt="stitched_moff_alpha">
                <figcaption>Moffitt Trash Cans Stitched w/ Alpha</figcaption>
            </figure>

            <figure>
                <img src="media/photos/stitched_doe_alpha.jpg" alt="stitched_doe_alpha">
                <figcaption>Doe Entrance Stitched w/ Alpha</figcaption>
            </figure>
        </div>

        <h2>Detecting Interest Points</h2>
        <p>
            Given an image, I wanted to detect potential corners in the image on which to align. I used Harris corner calculation to 
            do this, which does a process of smoothing and gradient calculations. In essence, this chose points which had a large 
            change in pixel intensities relative to the surrounding area. 
        </p>

        <div class="grey-image-row">
            <figure>
                <img src="media/photos/harris_corners.jpg" alt="harris_corners">
                <figcaption>Anchor House Bottom Interest Points</figcaption>
            </figure>
        </div>

        <h2>Choosing Good Interest Points: Adaptive Non-Maximal Suppression</h2>
        <p>
            Given many corners, I now had to choose a few corners -- corner matching is computationally expensive so I don't want 
            that many but I want them to be spread out to sample as much of the image as possible. I used the Adaptive Non-Maximal 
            Suppression algorithm to do this. 
        </p>

        <div class="grey-image-row">
            <figure>
                <img src="media/photos/anms.jpg" alt="anms">
                <figcaption>Anchor House Bottom ANMS</figcaption>
            </figure>
        </div>

        <h2>Getting Feature Descriptors</h2>
        <p>
            Now that I have a good set of corners, I needed a metric to compare the corners on -- a descriptor. To do this, I created 
            an 8 x 8 vector sampling each corner's neighboring 40 x 40 region every 5 pixels. I then normalized the vector gains such
            that the mean was 0 and the standard deviation was 1. Normalization is necessary because I wanted to have invariance to 
            ligting changes across comparisons.  
        </p>

        <div class="grey-image-row">
            <figure>
                <img src="media/photos/descriptor.jpg" alt="descriptor">
                <figcaption>8 x 8 Feature Descriptor</figcaption>
            </figure>
        </div>

        <h2>Matching Features</h2>
        <p>
            To match features, I compared descriptors of the chosen interest points with SSIM as the metric on how similar descriptor 
            were to each other. I then used Lowe's law of nearest neighbors to then determine which of the similar descriptors 
            actually represented correspondences. 
        </p>

        <div class="grey-image-row">
            <figure>
                <img src="media/photos/anchor_house_bottom_correspondences.jpg" alt="anchor_house_bottom_correspondences">
                <figcaption>Anchor House Bottom Auto-correspondences</figcaption>
            </figure>

            <figure>
                <img src="media/photos/anchor_house_middle_correspondences.jpg" alt="anchor_house_middle_correspondences">
                <figcaption>Anchor House Middle Auto-correspondences</figcaption>
            </figure>
        </div>

        <h2>RANSAC: Creating the Homography Matrix</h2>
        <p>
            Finally, I used 4-point RANSAC to choose which correspondences to use in creating the homography and then create the 
            resultant homographic matrix.  
        </p>

        <div class="grey-image-row">
            <figure>
                <img src="media/photos/anchor_house_bottom_ransac.jpg" alt="anchor_house_bottom_ransac">
                <figcaption>Anchor House Bottom RANSAC</figcaption>
            </figure>

            <figure>
                <img src="media/photos/anchor_house_middle_ransac.jpg" alt="anchor_house_middle_ransac">
                <figcaption>Anchor House Middle RANSAC</figcaption>
            </figure>
        </div>

        <h2>Conclusion</h2>
        <p>
            As can be seen through my less-than-ideal Matching Features and RANSAC results, I ran into a bug in my code that I wasn't 
            able to find by the project deadline which led to me not being able to automatically recover correct homographic matrices. That said, 
            I certainly am leaving this project having learned a lot of cool stuff. I think the coolest thing is honestly the power of 
            perception -- this is the first time I'm feeling that I'm writing a program that can perceive relevant points in an image on 
            its own, I just supply the framework to do so. It's getting me excited to see what's in store for the future and how these 
            ideas can be applied to perception in the robotics domain. 
        </p>

    </div>

</body>
</html>
